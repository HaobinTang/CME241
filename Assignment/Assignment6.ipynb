{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Assignment 6 by Haobin Tang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement Forward-View TD(Lambda) algorithm for Value Function Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_TD(size,TD_path, Lambda, gamma, alpha=\"Not fixed\"):\n",
    "    V, counts_dict=env(size)\n",
    "\n",
    "    for episode in TD_path:\n",
    "        for j,i in enumerate(episode):\n",
    "            _, G_lambda=get_G_lambda(j,episode,V,gamma,Lambda)\n",
    "            s=i[0]\n",
    "            counts_dict[s] += 1\n",
    "            if alpha==\"Not fixed\":\n",
    "                a = 1/counts_dict[s]\n",
    "            else:\n",
    "                a=alpha\n",
    "            V[s] = V[s] + a*(G_lambda-V[s])\n",
    "    return V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env(size):\n",
    "    V={}\n",
    "    counts_dict={}\n",
    "    for i in range(size):\n",
    "        V[i]=0\n",
    "        counts_dict[i]=0\n",
    "    return V, counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_G_lambda(j,episode,V,gamma,Lambda): \n",
    "    len_of_G=len(episode)-j\n",
    "    G_n=[0]*len_of_G\n",
    "    for k in range(j,len(episode)):\n",
    "        for l in range(len_of_G):\n",
    "            if l>=k-j:\n",
    "                G_n[l]=G_n[l]+episode[k][1]*gamma**(k-j)\n",
    "            if k<len(episode)-1:\n",
    "                if l==k-j:\n",
    "                    G_n[l]=G_n[l]+V[episode[k+1][0]]*gamma**(k-j+1)\n",
    "    G_lambda=0\n",
    "    for i in range(len(G_n)):\n",
    "        if i<len(G_n)-1:\n",
    "            G_lambda+=(1-Lambda)*(Lambda**i)*G_n[i]\n",
    "        else:\n",
    "            G_lambda+=(Lambda**i)*G_n[i]\n",
    "    return G_n, G_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TD_path contains the data of episodes. Each episode there are (state, r) pairs.\n",
    "TD_path=[\n",
    "    [[0,5],[1,3],[3,2],[0,2],[5,2]],\n",
    "    [[0,3],[2,3],[4,3]],\n",
    "    [[1,6],[2,4],[4,3],[1,2],[5,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "    [[1,6],[4,4],[4,3],[2,2],[1,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_n is [6.8, 10.13, 10.049, 11.4341, 12.090200000000001] \n",
      " G_lambda= 7.133640710000001\n"
     ]
    }
   ],
   "source": [
    "#test get_G_lambda()\n",
    "episode=[0,5],[1,3],[3,2],[0,2],[5,2]\n",
    "V={0: 1.0, 1: 2.0, 2: 2.0, 3: 3.0, 4: 2.0, 5: 1.0}\n",
    "G_n, G_lambda=get_G_lambda(0,episode,V,0.9,0.1)\n",
    "print(\"G_n is\",G_n,'\\n',\"G_lambda=\",G_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.952417844,\n",
       " 1: 8.028131271863701,\n",
       " 2: 6.457651846334045,\n",
       " 3: 7.418920907535256,\n",
       " 4: 8.333474088554961,\n",
       " 5: 2.0}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forward_TD(6,TD_path, 0.1, 0.9,\"Not fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1526921507242,\n",
       " 1: 2.700754587058949,\n",
       " 2: 1.0763228690358013,\n",
       " 3: 1.582766047279178,\n",
       " 4: 1.9367578567556742,\n",
       " 5: 0.38}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forward_TD(6,TD_path, 0.1, 0.9,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement Backward View TD(Lambda), i.e., Eligibility Traces algorithm for Value Function Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\delta_t=R_{t+1}+\\gamma V(S_{t+1})-V(S_t)$$\n",
    "$$V(s)=V(s)+\\alpha \\delta_t E_t(s)$$\n",
    "When $\\lambda = 0$, only current state is updated\n",
    "$$E_t(s)=1(S_t=s)$$\n",
    "$$V(s)=V(s)+\\alpha \\delta_t E_t(s)$$\n",
    "$$V(s)=V(s)+\\alpha \\delta_t$$\n",
    "When $\\lambda = 1$, credit is deferred until end of episode,Over the course of an episode, total update for TD(1) is the same as total update for MC, which we have proved in class:\n",
    "\n",
    "Consider an episode where s is visited once at time-step $k$,\n",
    "TD(1) eligibility trace discounts time since visit,\n",
    "$$E_t(s) = \\gamma E_{t−1}(s) + 1(S_t = s)$$\n",
    "$$E_t(s) =0 $$ if $t<k$\n",
    "$$E_t(s) =\\gamma^{t-k} $$ if $t>=k$\n",
    "\n",
    "By end of episode it accumulates total error\n",
    "$$\\delta_k+\\gamma\\delta_{k+1}+\\gamma^2\\delta_{k+2}+\\gamma^{T-k-1}\\delta_{T-1}$$\n",
    "$$=R_{t+1}+\\gamma V(S_{t+1})-V(S_t)$$\n",
    "$$+\\gamma R_{t+2}+\\gamma^2 V(S_{t+2})-\\gamma V(S_{t+1})$$\n",
    "$$...$$\n",
    "$$+\\gamma^{T-1-t} R_{T}+\\gamma^{T-t} V(S_{T})-\\gamma^{T-t-1} V(S_{T-1})$$\n",
    "$$=R_{t+1}+\\gamma R_{t+2}+...+\\gamma^{T-1-t} R_{T}-V(S_t)$$\n",
    "$$=G_t-V(S_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prove Prove that Offline Forward-View TD(Lambda) and Offline Backward View TD(Lambda) are equivalent in problem 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline update\n",
    "def Backward_TD(size,TD_path, Lambda,gamma,alpha=\"Not fixed\"):\n",
    "    V, counts_dict=env(size)\n",
    "    for episode in TD_path:\n",
    "        G_lambda=get_G_lambda_list(episode,V,gamma,Lambda)\n",
    "        for j,i in enumerate(episode):\n",
    "            s=i[0]\n",
    "            counts_dict[s] += 1\n",
    "            if alpha==\"Not fixed\":\n",
    "                a = 1/counts_dict[s]\n",
    "            else:\n",
    "                a=alpha\n",
    "            V[s] = V[s] + a*(G_lambda[j])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_G_lambda_list(episode,V,gamma,Lambda): \n",
    "    G_lambda=[0]*len(episode)\n",
    "    for j,i in enumerate(episode):\n",
    "        s=i[0]\n",
    "        r=i[1]\n",
    "        if j<len(episode)-1:\n",
    "            next_s=episode[j+1][0]\n",
    "            delta_j=r+gamma*V[next_s]-V[s]\n",
    "        else:\n",
    "            delta_j=r-V[s]\n",
    "        \n",
    "        for k in range(0,j+1):\n",
    "            G_lambda[k]+=delta_j*(Lambda*gamma)**(j-k)\n",
    "    return G_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_lambda is [6.13364071, 3.7071190000000005, 0.07909999999999992, 1.99, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#test get_G_lambda_list()\n",
    "episode=[0,5],[1,3],[3,2],[0,2],[5,2]\n",
    "V={0: 1.0, 1: 2.0, 2: 2.0, 3: 3.0, 4: 2.0, 5: 1.0}\n",
    "G_lambda=get_G_lambda_list(episode,V,0.9,0.1)\n",
    "print(\"G_lambda is\",G_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.009975688,\n",
       " 1: 7.630804343210887,\n",
       " 2: 6.015810307765591,\n",
       " 3: 7.271754216045634,\n",
       " 4: 6.753814199216089,\n",
       " 5: 2.0}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD_path=[\n",
    "    [[0,5],[1,3],[3,2],[0,2],[5,2]],\n",
    "    [[0,3],[2,3],[4,3]],\n",
    "    [[1,6],[2,4],[4,3],[1,2],[5,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "    [[1,6],[4,4],[4,3],[2,2],[1,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "]\n",
    "\n",
    "Backward_TD(6,TD_path, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1912401341380001,\n",
       " 1: 2.781332274429034,\n",
       " 2: 1.0307742563655233,\n",
       " 3: 1.6396252770882496,\n",
       " 4: 1.8639807300758666,\n",
       " 5: 0.38}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Backward_TD(6,TD_path, 0.1, 0.9,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement these algorithms as offline or online algorithms (offline means updates happen only after a full simulation trace, online means updates happen at every time step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from the above, there are slightly difference the forward and backward TD algorithms. The reason is that in my above design, the forward TD is online alogorithm, which use the V(s) updated in the same episode, while the forward TD is offline alogorithm, which use the V(s) updated from the last episode. We can see from the following example, where there is two state 0. In forward TD, the later state 0 use the updated $V(S_0)$ to calculate G, while in the backward TD, it uses the unchanged $V(S_0)$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_TD {0: 3.73389461, 1: 3.5831378341380002, 2: 0, 3: 6.4793092682, 4: 0, 5: 2.0}\n",
      "Backward_TD {0: 6.37778922, 1: 3.197658, 2: 0, 3: 2.1962, 4: 0, 5: 2.0}\n"
     ]
    }
   ],
   "source": [
    "TD_path=[\n",
    "    [[0,5],[1,3],[3,2],[0,2],[5,2]]\n",
    "]\n",
    "print(\"Forward_TD\",Forward_TD(6,TD_path, 0.1, 0.9))\n",
    "print(\"Backward_TD\",Backward_TD(6,TD_path, 0.1, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just have an episode, which each state appear at most once, the result will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_TD {0: 5.28778922, 1: 3.197658, 2: 0, 3: 2.1961999999999997, 4: 2.18, 5: 2.0}\n",
      "Backward_TD {0: 5.2877892200000005, 1: 3.197658, 2: 0, 3: 2.1962, 4: 2.18, 5: 2.0}\n"
     ]
    }
   ],
   "source": [
    "TD_path=[\n",
    "    [[0,5],[1,3],[3,2],[4,2],[5,2]]\n",
    "]\n",
    "print(\"Forward_TD\",Forward_TD(6,TD_path, 0.1, 0.9))\n",
    "print(\"Backward_TD\",Backward_TD(6,TD_path, 0.1, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, now I need to modify Forward_TD to offline version and Backward_TD to online version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_TD_offline(size,TD_path, Lambda, gamma, alpha=\"Not fixed\"):\n",
    "    V, counts_dict=env(size)\n",
    "\n",
    "    for episode in TD_path:\n",
    "        G_lambda_list=[]\n",
    "        for j,i in enumerate(episode):\n",
    "            s=i[0]\n",
    "            _, G_lambda=get_G_lambda(j,episode,V,gamma,Lambda)\n",
    "            G_lambda_list.append(G_lambda-V[s])\n",
    "        for j,i in enumerate(episode):\n",
    "            s=i[0]\n",
    "            counts_dict[s] += 1\n",
    "            if alpha==\"Not fixed\":\n",
    "                a = 1/counts_dict[s]\n",
    "            else:\n",
    "                a=alpha\n",
    "            V[s] = V[s] + a*(G_lambda_list[j])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_TD_offline {0: 4.009975688, 1: 7.630804343210888, 2: 6.015810307765592, 3: 7.271754216045635, 4: 6.753814199216088, 5: 2.0}\n",
      "Backward_TD {0: 4.009975688, 1: 7.630804343210887, 2: 6.015810307765591, 3: 7.271754216045634, 4: 6.753814199216089, 5: 2.0}\n"
     ]
    }
   ],
   "source": [
    "TD_path=[\n",
    "    [[0,5],[1,3],[3,2],[0,2],[5,2]],\n",
    "    [[0,3],[2,3],[4,3]],\n",
    "    [[1,6],[2,4],[4,3],[1,2],[5,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "    [[1,6],[4,4],[4,3],[2,2],[1,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "]\n",
    "print(\"Forward_TD_offline\",Forward_TD_offline(6,TD_path, 0.1, 0.9))\n",
    "print(\"Backward_TD\",Backward_TD(6,TD_path, 0.1, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we modify the Backward_TD to online version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_TD_online(size,TD_path, Lambda,gamma,alpha=\"Not fixed\"):\n",
    "    V, counts_dict=env(size)\n",
    "    for episode in TD_path:\n",
    "        for j,i in enumerate(episode):\n",
    "            G_lambda=get_G_lambda_list(episode,V,gamma,Lambda)\n",
    "            s=i[0]\n",
    "            counts_dict[s] += 1\n",
    "            if alpha==\"Not fixed\":\n",
    "                a = 1/counts_dict[s]\n",
    "            else:\n",
    "                a=alpha\n",
    "            V[s] = V[s] + a*(G_lambda[j])\n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_TD {0: 2.952417844, 1: 8.028131271863701, 2: 6.457651846334045, 3: 7.418920907535256, 4: 8.333474088554961, 5: 2.0}\n",
      "Backward_TD_online {0: 2.952417844, 1: 8.028131271863701, 2: 6.457651846334045, 3: 7.418920907535255, 4: 8.333474088554961, 5: 2.0}\n"
     ]
    }
   ],
   "source": [
    "TD_path=[\n",
    "    [[0,5],[1,3],[3,2],[0,2],[5,2]],\n",
    "    [[0,3],[2,3],[4,3]],\n",
    "    [[1,6],[2,4],[4,3],[1,2],[5,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "    [[1,6],[4,4],[4,3],[2,2],[1,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "]\n",
    "print(\"Forward_TD\",Forward_TD(6,TD_path, 0.1, 0.9))\n",
    "print(\"Backward_TD_online\",Backward_TD_online(6,TD_path, 0.1, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's perfect too! For now, we have finished the online and offline version of Forward_TD and Backward_TD_online. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test these algorithms on some example MDPs, compare them versus DP Policy Evaluation, and plot their accuracy as a function of Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP_transistion_Data={\n",
    "        0: {0:0.25, 1: 0.25, 2: 0.25, 3: 0.25},\n",
    "        1: {0:0, 1: 0, 2: 0.5, 3: 0.5},\n",
    "        2: {0:0, 1: 0.5, 2: 0, 3: 0.5},\n",
    "        3: {0:0, 1: 0, 2: 0, 3:1},\n",
    "    }\n",
    "\n",
    "Reward={0:2.5,1:2,2:2,3:3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP_transistion_Data={\n",
    "        0: {0:0.5, 1: 0.5},\n",
    "        1: {0:0, 1: 1},\n",
    "\n",
    "    }\n",
    "\n",
    "Reward={0:1,1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' To simplify as an MRP, we use the DP value function evaluation in HW2 to compute value function.\n",
    "The above algorithms are for (state, reward) pairs. Thus, the information of policy and state transition\n",
    "probability is in the data.\n",
    "'''\n",
    "def Solve_V(MP_transistion_Data,Reward,gama):\n",
    "    n=len(MP_transistion_Data)\n",
    "    V_matrix=np.zeros((n,n))\n",
    "    R_vector=np.zeros(n)\n",
    "    all_one=np.eye(n)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            V_matrix[i][j]=MP_transistion_Data[i][j]*gama\n",
    "    for i in range(n):\n",
    "        R_vector[i]=Reward[i]\n",
    "    \n",
    "    Result=np.dot(R_vector,np.linalg.inv(all_one-np.transpose(V_matrix)))\n",
    "    \n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of value function is \n",
      "[28.29912023 28.18181818 28.18181818 30.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"the result of value function is \" )\n",
    "print(Solve_V(MP_transistion_Data,Reward,0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory=[\n",
    "    [[0,2],[1,2],[2,2],[3,3]],\n",
    "    [[0,2],[1,2],[2,2],[1,2],[3,3]],\n",
    "    [[0,2],[1,2],[2,2],[1,2],[2,2],[3,3]],\n",
    "    [[0,2],[1,2],[2,2],[1,2],[2,2],[1,2],[3,3]],\n",
    "    [[0,2],[1,2],[2,2],[1,2],[2,2],[1,2],[2,2],[3,3]],\n",
    "    [[0,2],[1,2],[3,3]],\n",
    "    [[0,2],[2,2],[3,3]],\n",
    "    [[0,2],[2,2],[1,2],[3,3]],\n",
    "    [[0,2],[2,2],[3,3]],\n",
    "    [[0,2],[2,2],[1,2],[2,2],[3,3]],\n",
    "    [[0,2],[2,2],[1,2],[2,2],[1,2],[3,3]],\n",
    "    [[0,2],[2,2],[1,2],[2,2],[1,2],[3,3]],\n",
    "    [[0,2],[2,2],[1,2],[2,2],[1,2],[2,2],[3,3]],\n",
    "    [[0,4],[3,3]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a2655c0>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trueV=[8,7,7,3]\n",
    "plot_Lambda=[]\n",
    "plot_error=[]\n",
    "for Lambda in range(0,11):\n",
    "    result=Backward_TD(4,trajectory, Lambda/10, 0.9)\n",
    "    accuracy=0\n",
    "    for i in range(4):\n",
    "        accuracy+=(result[i]-trueV[i])**2/4\n",
    "    plot_Lambda.append(Lambda/10)\n",
    "    plot_error.append(accuracy)\n",
    "\n",
    "plt.plot(plot_Lambda,plot_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prove that Offline Forward-View TD(Lambda) and Offline Backward View TD(Lambda) are equivalent. We covered the proof of Lambda = 1 in class. Do the proof for arbitrary Lambda (similar telescoping argument as done in class) for the case where a state appears only once in an episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For general $\\lambda$, TD errors also telescope to $\\lambda$-error, $G_t^λ − V(S_t)$\n",
    "$$\\begin{aligned}\n",
    "G_t^\\lambda − V(S_t)=− V(S_t)&+(1-\\lambda)\\lambda^0(R_{t+1}+\\gamma V(S_{t+1})) \\\\\n",
    "&+(1-\\lambda)\\lambda^1(R_{t+1}+\\gamma R_{t+2}+\\gamma^2 V(S_{t+2}))\\\\\n",
    "&+(1-\\lambda)\\lambda^2(R_{t+1}+\\gamma R_{t+2}+\\gamma^2 R_{t+3}+\\gamma^3 V(S_{t+3}))\\\\\n",
    "&+...\\\\\n",
    "=− V(S_t)&+(\\gamma\\lambda)^0(R_{t+1}+\\gamma V(S_{t+1}-\\gamma \\lambda V(S_{t+1}))\\\\\n",
    "&+(\\gamma\\lambda)^1(R_{t+2}+\\gamma V(S_{t+2}-\\gamma \\lambda V(S_{t+2}))\\\\\n",
    "&+(\\gamma\\lambda)^2(R_{t+3}+\\gamma V(S_{t+3}-\\gamma \\lambda V(S_{t+3}))\\\\\n",
    "&+...\\\\\n",
    "=&(\\gamma\\lambda)^0(R_{t+1}+\\gamma V(S_{t+1}- V(S_{t}))\\\\\n",
    "&+(\\gamma\\lambda)^1(R_{t+2}+\\gamma V(S_{t+2}- V(S_{t+1}))\\\\\n",
    "&+(\\gamma\\lambda)^2(R_{t+3}+\\gamma V(S_{t+3}- V(S_{t+2}))\\\\\n",
    "&+...\\\\\n",
    "&=\\lambda_t+\\gamma\\lambda\\delta_{t+1}+(\\gamma\\lambda)^2\\delta_{t+2}+(\\gamma\\lambda)^{T}\\delta_{T}\n",
    "\\end{aligned}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
