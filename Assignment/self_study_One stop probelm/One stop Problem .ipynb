{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One stop prpblem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the settings. \n",
    "\n",
    "7 states:\n",
    "\n",
    "    state 0 means now\n",
    "    \n",
    "    state 1-5 means time day1 to day5\n",
    "    \n",
    "    state 6 means terminal (once we buy one asset, we stop because accoring to Problem2 the buyer buy one asset)\n",
    "   \n",
    "6 action:\n",
    "\n",
    "    action 0-4 means buy asset0-4\n",
    "    \n",
    "    action 5 means not buy and go to the next day(also state)\n",
    "    \n",
    "    \n",
    "Reward:\n",
    "    The benefit of buying each asset is randomly set but has a increasing trend. There is also time value in the reward because in the problem setup, it either is optimizing the execution price or minimizing number of counterparties the buyer talk to.\n",
    "    \n",
    "Data instruction:\n",
    "For each pair of states in (0,6) and actions in (0,5), P[state][action] is a\n",
    "tuple of the form (probability, nextstate, reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initial_data={\n",
    "    0:{0:0,1:0,2:0,3:0,4:0,5:0},\n",
    "    1:{0:0,1:0,2:0,3:0,4:0,5:0},\n",
    "    2:{0:0,1:0,2:0,3:0,4:0,5:0},\n",
    "    3:{0:0,1:0,2:0,3:0,4:0,5:0},\n",
    "    4:{0:0,1:0,2:0,3:0,4:0,5:0},\n",
    "    5:{0:0,1:0,2:0,3:0,4:0,5:0},\n",
    "    6:{0:0,1:0,2:0,3:0,4:0,5:0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data):\n",
    "    for i in range(0,len(data)-1):\n",
    "        for j in range(0,len(data[i])-1):\n",
    "            time_value=5-i\n",
    "            data[i][j]=(1,6,(random.random()*50*(i+1)/(i+2)+time_value))\n",
    "        data[i][len(data[i])-1]=(1,i+1,0)\n",
    "    for i in range(0,len(data[i])):\n",
    "        data[len(data)-1][i]=(1,6,0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: (1, 6, 24.472738431645716),\n",
       "  1: (1, 6, 29.61647337301111),\n",
       "  2: (1, 6, 26.672830669303004),\n",
       "  3: (1, 6, 15.490360700756945),\n",
       "  4: (1, 6, 25.468591360003312),\n",
       "  5: (1, 1, 0)},\n",
       " 1: {0: (1, 6, 19.290863364585064),\n",
       "  1: (1, 6, 14.854941014404773),\n",
       "  2: (1, 6, 26.775086288312114),\n",
       "  3: (1, 6, 4.755199910721819),\n",
       "  4: (1, 6, 16.267087711610202),\n",
       "  5: (1, 2, 0)},\n",
       " 2: {0: (1, 6, 7.671710564653766),\n",
       "  1: (1, 6, 8.379068812682302),\n",
       "  2: (1, 6, 40.41933731373332),\n",
       "  3: (1, 6, 23.521573110172138),\n",
       "  4: (1, 6, 11.425033091267373),\n",
       "  5: (1, 3, 0)},\n",
       " 3: {0: (1, 6, 14.12846515177489),\n",
       "  1: (1, 6, 31.712676597916754),\n",
       "  2: (1, 6, 16.597575242961376),\n",
       "  3: (1, 6, 36.20803427409019),\n",
       "  4: (1, 6, 30.531822212443807),\n",
       "  5: (1, 4, 0)},\n",
       " 4: {0: (1, 6, 13.166553076155543),\n",
       "  1: (1, 6, 36.55023996413347),\n",
       "  2: (1, 6, 36.37047096936288),\n",
       "  3: (1, 6, 26.565637206450692),\n",
       "  4: (1, 6, 7.67516664675924),\n",
       "  5: (1, 5, 0)},\n",
       " 5: {0: (1, 6, 18.235099396579574),\n",
       "  1: (1, 6, 39.316755312559096),\n",
       "  2: (1, 6, 32.37122607026338),\n",
       "  3: (1, 6, 30.73766612583836),\n",
       "  4: (1, 6, 35.30259819589228),\n",
       "  5: (1, 6, 0)},\n",
       " 6: {0: (1, 6, 0),\n",
       "  1: (1, 6, 0),\n",
       "  2: (1, 6, 0),\n",
       "  3: (1, 6, 0),\n",
       "  4: (1, 6, 0),\n",
       "  5: (1, 6, 0)}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=generate_data(Initial_data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Value_iteration in MDP to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(P, nS, nA, gamma=0.9, tol=1e-3):  \n",
    "    value_function = np.zeros(nS)\n",
    "    policy = np.zeros(nS, dtype=int)\n",
    "    while True:\n",
    "        prev_value_function = np.ones(nS)\n",
    "        for i in range(nS):\n",
    "            Qvalue = np.zeros(nA)\n",
    "            \n",
    "            for j in range(nA):\n",
    "                prob, next_state, reward = P[i][j]\n",
    "                Qvalue[j] = prob * (reward + gamma * value_function[next_state])\n",
    "            \n",
    "            prev_value_function[i]=np.max(Qvalue)\n",
    "            policy[i]=np.argmax(Qvalue)\n",
    "            \n",
    "        var=np.linalg.norm(prev_value_function-value_function, ord=np.inf)\n",
    "        if var>tol:\n",
    "            value_function=prev_value_function\n",
    "        else:\n",
    "            break\n",
    "    return value_function, policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_function= [32.73966322 36.37740358 40.41933731 36.20803427 36.55023996 39.31675531\n",
      "  0.        ]\n",
      "policy= [5 5 2 3 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "value_function,policy=value_iteration(data,len(data),len(data[1]))\n",
    "print(\"value_function=\",value_function)\n",
    "print(\"policy=\",policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shows that the optimal action in day 0 and 1 is waiting, buy asset 2 in day 2, buy asset 3 in day 3 and so on. The optimal value is 40.42 which means buy asset 2 in day 2 is the best option in this setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
