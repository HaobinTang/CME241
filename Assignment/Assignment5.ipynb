{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Assignment 5 by Haobin Tang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write code for the interface for tabular RL algorithms. The core of this interface should be a mapping from a (state, action) pair to a sampling of the (next state, reward) pair. It is important that this interface doesn't present the state-transition probability model or the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Build a simulator exmaple behind the interface. As I discussed with professor Rao, the simulator can be both determinisitic \n",
    "or stochastic, but we should assume we don't know in the RL interface and just send in (state, action) pair and \n",
    "get (next state, reward)\n",
    "'''\n",
    "def simulator_example(state, action):\n",
    "    next_state=np.random.binomial(20, 0.5, size=None)\n",
    "    action=state*action\n",
    "    return next_state, action     \n",
    "\n",
    "def get_mdp_rep_for_rl_tabular(data):\n",
    "    output=[]\n",
    "    for i in data:\n",
    "        next_state, action=simulator_example(i[0],i[1])\n",
    "        output.append([next_state,action])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 0], [15, 6], [7, 24], [10, 0], [10, 4]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[[0,5],[2,3],[12,2],[6,0],[4,1]]\n",
    "get_mdp_rep_for_rl_tabular(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement any tabular Monte-Carlo algorithm for Value Function prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC(size,mc_path, visit=\"first\"):\n",
    "    V, counts_dict,_=env(size)\n",
    "    for episode in mc_path:\n",
    "        _, _, first_visit=env(size)\n",
    "        for i in episode:\n",
    "            s=i[0]\n",
    "            G=i[1]\n",
    "            if  visit==\"first\":\n",
    "                if first_visit[s]==0:\n",
    "                    counts_dict[s] += 1\n",
    "                    c = counts_dict[s]\n",
    "                    V[s] = (V[s] * (c - 1) + G) / c\n",
    "                    first_visit[s]=1\n",
    "            if  visit==\"every\":\n",
    "                counts_dict[s] += 1\n",
    "                c = counts_dict[s]\n",
    "                V[s] = (V[s] * (c - 1) + G) / c\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env(size):\n",
    "    V={}\n",
    "    counts_dict={}\n",
    "    first_visit={}\n",
    "    for i in range(size):\n",
    "        V[i]=0\n",
    "        counts_dict[i]=0\n",
    "        first_visit[i]=0\n",
    "    return V, counts_dict, first_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_path contains the data of episodes. Each episode there are (state, G) pairs.\n",
    "mc_path=[\n",
    "    [[0,5],[1,3],[3,2],[0,2],[5,2]],\n",
    "    [[0,3],[2,3],[4,3]],\n",
    "    [[1,6],[2,4],[4,3],[1,2],[5,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "    [[1,6],[4,4],[4,3],[2,2],[1,2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3.3333333333333335, 1: 5.25, 2: 3.0, 3: 3.0, 4: 3.25, 5: 2.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC(6, mc_path, \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3.0, 1: 4.166666666666667, 2: 3.0, 3: 2.6666666666666665, 4: 3.2, 5: 2.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC(6, mc_path,\"every\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement tabular 1-step TD algorithm for Value Function prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TD(size,TD_path,gamma,alpha=0):\n",
    "    V, counts_dict=env(size)\n",
    "    \n",
    "    for episode in TD_path:\n",
    "        for j,i in enumerate(episode):\n",
    "            s=i[0]\n",
    "            r=i[1]\n",
    "            if j<len(episode)-1:\n",
    "                next_s=episode[j+1][0]\n",
    "            else:\n",
    "                next_s=i[0]\n",
    "            counts_dict[s] += 1\n",
    "            if alpha==0:\n",
    "                alpha = 1/counts_dict[s]\n",
    "            V[s] = V[s] + alpha*(r+gamma*V[next_s]-V[s])\n",
    "    return V \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env(size):\n",
    "    V={}\n",
    "    counts_dict={}\n",
    "    for i in range(size):\n",
    "        V[i]=0\n",
    "        counts_dict[i]=0\n",
    "    return V, counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TD_path contains the data of episodes. Each episode there are (state, r) pairs.\n",
    "TD_path=[\n",
    "    [[0,5],[1,3],[3,2],[0,2],[5,2]],\n",
    "    [[0,3],[2,3],[4,3]],\n",
    "    [[1,6],[2,4],[4,3],[1,2],[5,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "    [[1,6],[4,4],[4,3],[2,2],[1,2]],\n",
    "    [[1,6],[3,4],[4,3],[3,2],[0,2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 7.0, 1: 11.0, 2: 27.0, 3: 7.0, 4: 17.0, 5: 4.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD(6,TD_path,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6.08,\n",
       " 1: 13.432576000000001,\n",
       " 2: 16.391424,\n",
       " 3: 7.6874752,\n",
       " 4: 14.4373248,\n",
       " 5: 3.2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD(6,TD_path,1,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prove that fixed learning rate (step size alpha) for MC is equivalent to an exponentially decaying average of episode returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental Monte-Carlo Updates. In non-stationary problems, it can be useful to track a running\n",
    " mean, i.e. forget old episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V(S_t)=V(S_t)+\\alpha(G_t-V(S_t))$$\n",
    "$$V(S_{t_0})=0$$\n",
    "$$V(S_{t_1})=0+\\alpha(G_{t_1}-0)=\\alpha G_{t_1}$$\n",
    "$$V(S_{t_2})=\\alpha G_{t_1}+\\alpha(G_{t_2}-\\alpha G_{t_1})=\\alpha*(1-\\alpha)G_{t_1}+\\alpha G_{t_2}$$\n",
    "$$...$$\n",
    "$$V(S_{t})=\\alpha*(1-\\alpha)^{t-1}G_{t_1}+\\alpha*(1-\\alpha)^{t-2}G_{t_2}+...+ \\alpha G_{t} $$\n",
    "\n",
    "Therefore, fixed learning rate (step size alpha) for MC is equivalent to an exponentially decaying average of episode returns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
